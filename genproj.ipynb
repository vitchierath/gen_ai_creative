{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRXyHuuAWTNx0fhPGQsZCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitchierath/gen_ai_creative/blob/main/genproj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlJuVwU_HUC2",
        "outputId": "e67727cf-0ba6-4db1-a5e2-ca7bba5283e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.32.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.30.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.2->diffusers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgDAvrqpHQbr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import cv2\n",
        "import numpy as np\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
        "from transformers import pipeline as hf_pipeline, BlipProcessor, BlipForConditionalGeneration\n",
        "import torch\n",
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "use_cpu = True  # Set to False for GPU after debugging\n",
        "\n",
        "# Initialize models\n",
        "def load_model(model_class, model_id, pipeline_type=\"standard\", retries=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            device = \"cpu\" if use_cpu else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            pipe = model_class.from_pretrained(\n",
        "                model_id,\n",
        "                safety_checker=None,\n",
        "                torch_dtype=torch.float32 if device == \"cpu\" else torch.float16\n",
        "            )\n",
        "            pipe = pipe.to(device)\n",
        "            print(f\"âœ… {model_id} ({pipeline_type}) loaded on {device}.\")\n",
        "            return pipe\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Attempt {attempt+1}/{retries} failed: {e}\")\n",
        "            if attempt < retries - 1:\n",
        "                time.sleep(2)\n",
        "            if device == \"cuda\" and attempt == retries - 1:\n",
        "                print(f\"âš ï¸ Falling back to CPU.\")\n",
        "                device = \"cpu\"\n",
        "    raise Exception(f\"Failed to load {model_id} after {retries} attempts.\")\n",
        "\n",
        "# Use reliable publicly available models\n",
        "try:\n",
        "    # Try stabilityai/stable-diffusion-2-1 for good quality without requiring too much memory\n",
        "    pipe_realistic = load_model(StableDiffusionPipeline, \"stabilityai/stable-diffusion-2-1\", \"standard\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Failed to load SD 2.1. Falling back to SD 1.5...\")\n",
        "    try:\n",
        "        # Last resort - original SD 1.5\n",
        "        pipe_realistic = load_model(StableDiffusionPipeline, \"runwayml/stable-diffusion-v1-5\", \"standard\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âš ï¸ Critical error loading any stable diffusion model: {e2}\")\n",
        "        exit(1)\n",
        "\n",
        "try:\n",
        "    # Use the same model for img2img to maintain consistency\n",
        "    model_id = pipe_realistic.config._name_or_path\n",
        "    pipe_img2img = load_model(StableDiffusionImg2ImgPipeline, model_id, \"img2img\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Failed to load matching img2img model. Trying SD 1.5...\")\n",
        "    try:\n",
        "        pipe_img2img = load_model(StableDiffusionImg2ImgPipeline, \"runwayml/stable-diffusion-v1-5\", \"img2img\")\n",
        "    except Exception as e2:\n",
        "        print(f\"âš ï¸ Critical error loading img2img model: {e2}\")\n",
        "        exit(1)\n",
        "\n",
        "try:\n",
        "    generator = hf_pipeline(\"text-generation\", model=\"gpt2\")\n",
        "    print(\"âœ… GPT-2 loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Failed to load GPT-2: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "try:\n",
        "    blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "    if not use_cpu and torch.cuda.is_available():\n",
        "        blip_model = blip_model.to(\"cuda\")\n",
        "    print(\"âœ… BLIP loaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Failed to load BLIP: {e}\")\n",
        "    exit(1)\n",
        "\n",
        "# Generate prompt\n",
        "def generate_prompt(input_text, is_initial=True, prev_image_filename=None):\n",
        "    if is_initial:\n",
        "        return f\"A photorealistic scene depicting {input_text}, highly detailed, professional photography, sharp focus, 8k.\"\n",
        "    try:\n",
        "        if prev_image_filename and os.path.exists(prev_image_filename):\n",
        "            image = Image.open(prev_image_filename).convert(\"RGB\")\n",
        "            inputs = blip_processor(images=image, return_tensors=\"pt\")\n",
        "            if not use_cpu and torch.cuda.is_available():\n",
        "                inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "            outputs = blip_model.generate(**inputs)\n",
        "            prev_description = blip_processor.decode(outputs[0], skip_special_tokens=True)\n",
        "            image.close()\n",
        "        else:\n",
        "            prev_description = \"the previous scene\"\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ BLIP analysis error: {e}\")\n",
        "        prev_description = \"the previous scene\"\n",
        "    return f\"A photorealistic scene evolving from '{prev_description}', incorporating {input_text}, highly detailed, professional photography, sharp focus, 8k.\"\n",
        "\n",
        "# Scene analysis with BLIP\n",
        "def analyze_scene(image_filename):\n",
        "    try:\n",
        "        if os.path.exists(image_filename):\n",
        "            image = Image.open(image_filename).convert(\"RGB\")\n",
        "            inputs = blip_processor(images=image, return_tensors=\"pt\")\n",
        "            if not use_cpu and torch.cuda.is_available():\n",
        "                inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "            outputs = blip_model.generate(**inputs)\n",
        "            description = blip_processor.decode(outputs[0], skip_special_tokens=True)\n",
        "            image.close()\n",
        "            return description if description else \"A realistic scene.\"\n",
        "        return \"A realistic scene.\"\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Scene analysis error: {e}\")\n",
        "        return \"A realistic scene.\"\n",
        "\n",
        "# Generate dialogue\n",
        "def generate_dialogue(scene_analysis):\n",
        "    try:\n",
        "        prompt = (\n",
        "            f\"Scene: '{scene_analysis}'. \"\n",
        "            f\"Create a 1-2 line dialogue for characters, capturing the mood.\"\n",
        "        )\n",
        "        dialogue = generator(\n",
        "            prompt, max_new_tokens=30, do_sample=True, temperature=0.9\n",
        "        )[0]['generated_text']\n",
        "        dialogue = dialogue[len(prompt):].strip()\n",
        "        dialogue = dialogue[:dialogue.rfind(\".\") + 1] if \".\" in dialogue else dialogue\n",
        "        return dialogue if dialogue else \"A quiet moment unfolds.\"\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Dialogue error: {e}\")\n",
        "        return \"A quiet moment unfolds.\"\n",
        "\n",
        "# Create comic panel\n",
        "def create_comic_panel(image_filenames, dialogues):\n",
        "    try:\n",
        "        images = [Image.open(f).convert(\"RGB\").resize((256, 256)) for f in image_filenames]\n",
        "        num_images = len(images)\n",
        "        panel_width = 256 * min(num_images, 4)  # Max 4 panels per row\n",
        "        panel_height = 320  # Space for dialogue\n",
        "        comic = Image.new(\"RGB\", (panel_width, panel_height), \"white\")\n",
        "        draw = ImageDraw.Draw(comic)\n",
        "\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 14)\n",
        "        except:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "        for i, img in enumerate(images):\n",
        "            x = (i % 4) * 256\n",
        "            comic.paste(img, (x, 0))\n",
        "            dialogue = dialogues[i][:40]  # Truncate for space\n",
        "            draw.text((x + 10, 260), dialogue, fill=\"black\", font=font)\n",
        "            img.close()\n",
        "\n",
        "        output_filename = f\"comic_{int(time.time())}.png\"\n",
        "        comic.save(output_filename)\n",
        "        comic.close()\n",
        "        return output_filename\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Comic panel error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create video\n",
        "def create_video(image_filenames):\n",
        "    try:\n",
        "        output_filename = f\"video_{int(time.time())}.mp4\"\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "        out = cv2.VideoWriter(output_filename, fourcc, 1.0, (256, 256))\n",
        "\n",
        "        for f in image_filenames:\n",
        "            if os.path.exists(f):\n",
        "                img = cv2.imread(f)\n",
        "                img = cv2.resize(img, (256, 256))\n",
        "                out.write(img)\n",
        "                for _ in range(2):  # 3 seconds at 1 fps\n",
        "                    out.write(img)\n",
        "\n",
        "        out.release()\n",
        "        return output_filename\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Video error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Main loop\n",
        "history = []\n",
        "session_log = []\n",
        "last_image_filename = None\n",
        "is_initial = True\n",
        "\n",
        "print(\"ğŸ§  Realistic Art Odyssey Generator Activated!\")\n",
        "print(\"â†’ Enter initial prompt (e.g., 'two rows of soldiers facing each other').\")\n",
        "print(\"â†’ Provide follow-up instructions (e.g., 'add a stormy sky').\")\n",
        "print(\"â†’ Type 'stop' to generate story and choose comic or video.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"ğŸŒ€ Input: \").strip()\n",
        "    if user_input.lower() == \"stop\":\n",
        "        break\n",
        "    if not user_input:\n",
        "        print(\"âš ï¸ Input cannot be empty.\\n\")\n",
        "        continue\n",
        "\n",
        "    input_type = \"initial prompt\" if is_initial else \"follow-up instruction\"\n",
        "    current_prompt = generate_prompt(user_input, is_initial, last_image_filename)\n",
        "    is_initial = False\n",
        "\n",
        "    try:\n",
        "        timestamp = int(time.time())\n",
        "        image_filename = f\"art_{timestamp}.png\"\n",
        "\n",
        "        # For simplicity and reliability, use 512x512 as standard size\n",
        "        height = 512\n",
        "        width = 512\n",
        "\n",
        "        if input_type == \"initial prompt\" or last_image_filename is None or not os.path.exists(last_image_filename):\n",
        "            # Generate a new image with the text-to-image pipeline\n",
        "            print(f\"Generating new image for prompt: '{current_prompt}'\")\n",
        "            image = pipe_realistic(\n",
        "                current_prompt,\n",
        "                guidance_scale=7.5,\n",
        "                height=height,\n",
        "                width=width,\n",
        "                num_inference_steps=30\n",
        "            ).images[0]\n",
        "        else:\n",
        "            # Try image-to-image with explicit error handling\n",
        "            try:\n",
        "                print(f\"Attempting img2img with prompt: '{current_prompt}'\")\n",
        "                # Open and convert the initial image\n",
        "                init_image = Image.open(last_image_filename).convert(\"RGB\")\n",
        "                # Resize to expected dimensions\n",
        "                init_image = init_image.resize((height, width), Image.LANCZOS)\n",
        "\n",
        "                # Debug info\n",
        "                print(f\"Input image type: {type(init_image)}, size: {init_image.size}\")\n",
        "\n",
        "                # Run img2img pipeline with explicit parameters\n",
        "                result = pipe_img2img(\n",
        "                    prompt=current_prompt,\n",
        "                    image=init_image,  # Use 'image' parameter name instead of 'init_image'\n",
        "                    strength=0.75,     # How much to transform the image (0-1)\n",
        "                    guidance_scale=7.5,\n",
        "                    num_inference_steps=30\n",
        "                )\n",
        "                image = result.images[0]\n",
        "                init_image.close()\n",
        "                print(\"âœ… Img2img successful\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Img2img failed: {e}. Generating new image.\")\n",
        "                # Fallback to text2img if img2img fails\n",
        "                image = pipe_realistic(\n",
        "                    current_prompt,\n",
        "                    guidance_scale=7.5,\n",
        "                    height=height,\n",
        "                    width=width,\n",
        "                    num_inference_steps=30\n",
        "                ).images[0]\n",
        "\n",
        "        # Resize to 256x256 for consistency with video/comic functions\n",
        "        image = image.resize((256, 256), Image.LANCZOS)\n",
        "        image.save(image_filename)\n",
        "\n",
        "        # Generate analysis and dialogue\n",
        "        scene_analysis = analyze_scene(image_filename)\n",
        "        dialogue = generate_dialogue(scene_analysis)\n",
        "\n",
        "        # Add to history\n",
        "        history.append((user_input, input_type, current_prompt, image_filename, scene_analysis, dialogue))\n",
        "        session_log.append(\n",
        "            f\"Input: {user_input} ({input_type})\\nImage: {image_filename}\\nAnalysis: {scene_analysis}\\nDialogue: {dialogue}\\n\"\n",
        "        )\n",
        "\n",
        "        last_image_filename = image_filename\n",
        "\n",
        "        print(f\"âœ… Image saved: {image_filename}\")\n",
        "        print(f\"ğŸ“Š Analysis: {scene_analysis}\")\n",
        "        print(f\"ğŸ’¬ Dialogue: {dialogue}\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Generation error: {e}\\n\")\n",
        "        continue\n",
        "\n",
        "# Save session log\n",
        "try:\n",
        "    with open(f\"session_log_{int(time.time())}.txt\", \"w\") as f:\n",
        "        f.write(\"\\n\".join(session_log))\n",
        "    print(\"âœ… Session log saved.\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Failed to save session log: {e}\")\n",
        "\n",
        "# Generate story\n",
        "def generate_final_story(history):\n",
        "    print(\"\\nğŸ§  Generating Story...\\n\")\n",
        "    intro = \"A journey through realistic scenes:\\n\"\n",
        "    for i, (input_text, input_type, prompt, filename, analysis, dialogue) in enumerate(history):\n",
        "        intro += (\n",
        "            f\"\\nScene {i+1} â€” Input: '{input_text}' ({input_type})\\n\"\n",
        "            f\"Image: {filename}\\nAnalysis: {analysis}\\nDialogue: {dialogue}\\n\"\n",
        "        )\n",
        "\n",
        "    intro += \"\\nAs the journey halted, the scenes formed a compelling narrative...\\n\"\n",
        "\n",
        "    try:\n",
        "        story = generator(\n",
        "            intro, max_new_tokens=300, do_sample=True, temperature=0.9\n",
        "        )[0]['generated_text']\n",
        "        story = story[:story.rfind(\".\") + 1]\n",
        "        return story\n",
        "    except Exception as e:\n",
        "        return f\"âš ï¸ Story generation failed: {e}\"\n",
        "\n",
        "final_story = generate_final_story(history)\n",
        "print(\"ğŸ“– STORY OUTPUT:\\n\")\n",
        "print(final_story)\n",
        "\n",
        "# Choose output\n",
        "if history:\n",
        "    print(\"\\nğŸ¨ Choose output:\")\n",
        "    print(\"1. Comic panel (with dialogues)\")\n",
        "    print(\"2. Video (image sequence)\")\n",
        "    choice = input(\"Enter 1 or 2: \").strip()\n",
        "\n",
        "    image_filenames = [h[3] for h in history]\n",
        "    dialogues = [h[5] for h in history]\n",
        "\n",
        "    if choice == \"1\":\n",
        "        comic_filename = create_comic_panel(image_filenames, dialogues)\n",
        "        if comic_filename:\n",
        "            print(f\"âœ… Comic panel saved: {comic_filename}\")\n",
        "    elif choice == \"2\":\n",
        "        video_filename = create_video(image_filenames)\n",
        "        if video_filename:\n",
        "            print(f\"âœ… Video saved: {video_filename}\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Invalid choice.\")\n",
        "\n",
        "if not use_cpu:\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            print(\"âœ… GPU memory cleared.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ GPU memory cleanup error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bLrmLqXEHVzk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}